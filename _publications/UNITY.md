---
title: "Agree to Disagree: Robust Anomaly Detection with Noisy Labels"
collection: publications
permalink: /publication/UNITY
excerpt: "Due to the scarcity of reliable anomaly labels, recent anomaly detection methods leveraging noisy auto-generated labels either select clean samples or refurbish noisy labels. However, both approaches struggle due to the unique properties of anomalies. Sample selection often fails to separate sufficiently many clean anomaly samples from noisy ones, while label refurbishment erroneously refurbish marginal clean samples. To overcome these limitations, we design Unity, the first learning-from-noisy-labels (LNL) approach for anomaly detection that elegantly leverages the merits of both sample selection and label refurbishment to iteratively prepare a diverse clean sample set for network training. Unity uses a pair of deep anomaly networks to collaboratively select samples with clean labels based on prediction agreement, followed by a disagreement resolution mechanism to capture marginal samples with clean labels. Thereafter, Unity utilizes unique properties of anomalies to design an anomaly-centric contrastive learning strategy that accurately refurbishes the remaining noisy labels. The resulting set composed of selected and refurbished clean samples is used to train the anomaly networks in the next training round. Our experimental study on 10 real-world benchmark datasets demonstrates that Unity consistently outperforms state-of-the-art LNL techniques by up to 0.31 in F-1 Score (0.52 to 0.83)."
date: 2025-02-11
venue: "Proceedings of the ACM on Management of Data (SIGMOD)"
paperurl: "https://dl.acm.org/doi/10.1145/3709657?cid=99659850355"
citation: "Dennis M. Hofmann, Peter M. VanNostrand, Lei Ma, Huayi Zhang, Joshua C. DeOliveira, Lei Cao, and Elke A. Rundensteiner. 2025. Agree to Disagree: Robust Anomaly Detection with Noisy Labels. Proc. ACM Manag. Data 3, 1, Article 7 (February 2025), 24 pages. https://doi.org/10.1145/3709657"
---

<link rel="stylesheet" type="text/css" media="all" href="/assets/css/widearticle.css" />

Due to the scarcity of reliable anomaly labels, recent anomaly detection methods leveraging noisy auto-generated labels either select clean samples or refurbish noisy labels. However, both approaches struggle due to the unique properties of anomalies. Sample selection often fails to separate sufficiently many clean anomaly samples from noisy ones, while label refurbishment erroneously refurbish marginal clean samples. To overcome these limitations, we design Unity, the first learning-from-noisy-labels (LNL) approach for anomaly detection that elegantly leverages the merits of both sample selection and label refurbishment to iteratively prepare a diverse clean sample set for network training. Unity uses a pair of deep anomaly networks to collaboratively select samples with clean labels based on prediction agreement, followed by a disagreement resolution mechanism to capture marginal samples with clean labels. Thereafter, Unity utilizes unique properties of anomalies to design an anomaly-centric contrastive learning strategy that accurately refurbishes the remaining noisy labels. The resulting set composed of selected and refurbished clean samples is used to train the anomaly networks in the next training round. Our experimental study on 10 real-world benchmark datasets demonstrates that Unity consistently outperforms state-of-the-art LNL techniques by up to 0.31 in F-1 Score (0.52 to 0.83).

Downloads: [Paper](https://dl.acm.org/doi/10.1145/3709657?cid=99659850355) ‚èê [Code](https://github.com/dhofmann34/Unity)